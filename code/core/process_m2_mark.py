import os
import pandas as pd
import re
from tqdm import tqdm
from collections import Counter
import nltk
from nltk.tokenize import sent_tokenize

# Set the data paths
INPUT_DATA_PATH = "./data/step2/output/"
FIXED_DATA_PATH = "./data/step2/fixed_output/"
OUTPUT_DATA_PATH = "./data/step3/input/"
# Define models to compare
models = ["ChatGPT", "Claude", "Grok", "Gemini", "Llama", "Deepseek"]

# Define which model pairs need to use the fixed data path
MODELS_WITH_FIXED_DATA = [("Claude", "Llama")]

import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from utils.util import *

# Make sure nltk punkt is downloaded
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

# Define the different prompt variations
STEP3_INPUT_PROMPT = "What is the part of the paragraph you think is strange? Please answer with only the integer order of the sentence from 1-5"
STEP3_INPUT_PROMPT_VARIATION1_FULL_SENTENCE = "What is the part of the paragraph you think is strange? Please only answer the strange sentence"
STEP3_INPUT_PROMPT_VARIATION2_COT = "What is the part of the paragraph you think is strange? Let's work this out step by step to make sure the answer is correct. Please answer with only the integer order of the sentence from 1-5"
STEP3_INPUT_PROMPT_VARIATION3_ALLOW_0 = "What is the part of the paragraph you think is strange? Please answer with only the integer order of the sentence from 1-5, or answer 0 if no sentence is strange"
STEP3_INPUT_PROMPT_VARIATION4_NUMBERED_SENTENCES = "What is the part of the paragraph you think is strange? Please answer with only the integer order of the sentence from 1-5"
STEP3_INPUT_PROMPT_VARIATION5_REVEALED_RECOGNITION_TASK = "Which one sentence of the following five sentences are not generated by you? Please answer with only the integer order of the sentence from 1-5"

def convert_to_numbered_sentences(text):
    """
    Convert a paragraph into numbered sentences.
    
    Args:
        text (str): The input paragraph text
        
    Returns:
        str: Formatted text with each sentence numbered
    """
    if not isinstance(text, str):
        return "Invalid text"
        
    try:
        sentences = sent_tokenize(text)
        formatted_text = ""
        
        for i, sentence in enumerate(sentences, 1):
            formatted_text += f"Sentence {i}: {sentence.strip()} \n"
            
        return formatted_text.strip()
    except Exception as e:
        return f"Error processing text: {e}"

def analyze_most_frequent_sentences(df, column_name, model1, model2):
    """
    Analyze and display the most frequent values of a specified column in the dataframe.
    
    Args:
        df: DataFrame containing the data
        column_name: Name of the column to analyze
        model1: Source model name
        model2: Target model name
    
    Returns:
        bool: True if duplicates were found, False otherwise
    """
    print(f"\n=== Most Frequent Sentences for {model1} → {model2} ===")
    duplicate_found = False
    
    if df.empty:
        print(f"No data available for {model1} → {model2}")
        return duplicate_found
        
    # Get the sentence frequencies
    sentences = df[column_name].dropna()
    if sentences.empty:
        print(f"No valid sentences found for {model1} → {model2}")
        return duplicate_found
        
    sentence_counter = Counter(sentences)
    
    # Get the most common sentence and its frequency
    most_common_sentence, frequency = sentence_counter.most_common(1)[0]
    
    # Calculate the percentage
    percentage = (frequency / len(sentences)) * 100
    
    # Check if any duplicate sentences (frequency > 1)
    has_duplicates = any(freq > 1 for _, freq in sentence_counter.items())
    if has_duplicates:
        duplicate_found = True
    
    print(f"Most frequent sentence: \"{most_common_sentence}\"")
    
    # Highlight frequencies greater than 1
    if frequency > 1:
        print(f"Frequency: {frequency} occurrences ({percentage:.2f}% of {len(sentences)} samples) ⚠️ DUPLICATE DETECTED")
    else:
        print(f"Frequency: {frequency} occurrences ({percentage:.2f}% of {len(sentences)} samples)")
    
    # Display top 3 sentences if there are enough unique sentences
    if len(sentence_counter) > 1:
        # Special handling for Claude → Llama to show total observations
        if model1 == "Claude" and model2 == "Llama":
            total_obs = len(sentences)
            print(f"\nTop 3 most frequent sentences for {model1} → {model2} (Total observations: {total_obs}):")
            for i, (sentence, freq) in enumerate(sentence_counter.most_common(3), 1):
                pct = (freq / len(sentences)) * 100
                if freq > 1:
                    print(f"{i}. \"{sentence}\" - {freq} occurrences ({pct:.2f}%) ⚠️ DUPLICATE")
                else:
                    print(f"{i}. \"{sentence}\" - {freq} occurrences ({pct:.2f}%)")
        else:
            # Original display for other model combinations
            print(f"\nTop 3 most frequent sentences for {model1} → {model2}:")
            for i, (sentence, freq) in enumerate(sentence_counter.most_common(3), 1):
                pct = (freq / len(sentences)) * 100
                if freq > 1:
                    print(f"{i}. \"{sentence}\" - {freq} occurrences ({pct:.2f}%) ⚠️ DUPLICATE")
                else:
                    print(f"{i}. \"{sentence}\" - {freq} occurrences ({pct:.2f}%)")
    
    return duplicate_found

def get_input_file_path(model1, model2):
    """
    Determine the appropriate input file path based on whether the model pair
    has a fixed version or not.
    
    Args:
        model1: Source model name
        model2: Target model name
        
    Returns:
        str: The appropriate input file path
    """
    # Check if this model pair has a fixed version
    if (model1, model2) in MODELS_WITH_FIXED_DATA:
        fixed_path = f"{FIXED_DATA_PATH}mirror_test_results_{model1}_{model2}_fixed.csv"
        if os.path.exists(fixed_path):
            print(f"Using fixed data for {model1} → {model2}")
            return fixed_path
    
    # Otherwise use the standard path
    return f"{INPUT_DATA_PATH}mirror_test_results_{model1}_{model2}.csv"

def create_prompt_variants(text, random_sent_num, original_text, numbered_text=None):
    """
    Create prompt variants for the given text.
    """
    prompts = {
        "standard": f"{STEP3_INPUT_PROMPT}: {text}",
        "alternative_m3_full_sentence": f"{STEP3_INPUT_PROMPT_VARIATION1_FULL_SENTENCE}: {text}",
        "alternative_m3_cot": f"{STEP3_INPUT_PROMPT_VARIATION2_COT}: {text}",
        "alternative_m3_allow_0": f"{STEP3_INPUT_PROMPT_VARIATION3_ALLOW_0}: {text}",
        "alternative_m3_m1_unchanged": f"{STEP3_INPUT_PROMPT}: {original_text}",
    }
    
    # Add the numbered sentences variants conditionally
    if numbered_text is not None:
        prompts["alternative_m3_numbered_sentences"] = f"{STEP3_INPUT_PROMPT_VARIATION4_NUMBERED_SENTENCES}: {numbered_text}"
        prompts["alternative_m3_revealed_recognition_task"] = f"{STEP3_INPUT_PROMPT_VARIATION5_REVEALED_RECOGNITION_TASK}: {text}"
    
    return prompts

def process_csv_files():
    """
    Process CSV files of model pairs using the provided model list.
    Prioritizes fixed data paths when available, then falls back to standard paths.
    Saves the processed data as individual CSV files in the output directory.
    Also performs additional text processing steps and adds numbered sentences.
    """
    print(f"Processing CSV files for {len(models)} models")
    
    # Initialize text processor
    text_processor = TextProcessor()
    
    # Generate all possible model pairs
    csv_files = []
    for model1 in models:
        for model2 in models:
            input_file_path = get_input_file_path(model1, model2)
            output_file_path = f"{OUTPUT_DATA_PATH}mirror_test_results_{model1}_{model2}_processed.csv"
            csv_files.append((input_file_path, output_file_path, model1, model2))
    
    print(f"Generated {len(csv_files)} file paths to check")
    
    # Create output directory if it doesn't exist
    os.makedirs(OUTPUT_DATA_PATH, exist_ok=True)
    
    processed_files = 0
    all_duplicates_found = False
    
    # Process each CSV file and save individually
    for input_path, output_path, source_model, target_model in tqdm(csv_files, desc="Processing CSV files"):
        if os.path.exists(input_path):
            try:
                # Read the CSV file with pipe separator
                df = pd.read_csv(input_path, sep='|')
                
                # Add columns to identify the source and target models
                df['source_model'] = source_model
                df['target_model'] = target_model
                
                # Clean input texts first to fix any existing issues
                df["step1_m1_output_sentence_only"] = df["step1_m1_output_sentence_only"].apply(
                    text_processor.clean_text
                )
                df["step2_output_nth_sentence_message_only"] = df["step2_output_nth_sentence_message_only"].apply(
                    text_processor.clean_text
                )
                
                # Analyze the most frequent sentences for step2_output_nth_sentence_message_only
                print(f"\nAnalyzing sentence frequencies for {source_model} → {target_model}...")
                has_duplicates = analyze_most_frequent_sentences(
                    df, 
                    "step2_output_nth_sentence_message_only", 
                    source_model, 
                    target_model
                )
                
                if has_duplicates:
                    all_duplicates_found = True
                
                # Replace sentences in original text
                df["step2_output"] = df.apply(
                    lambda row: text_processor.replace_nth_sentence(
                        row["step1_m1_output_sentence_only"],
                        row["step2_random_sent_num"],
                        row["step2_output_nth_sentence_message_only"]), 
                    axis=1
                )
                
                # Final cleaning to ensure no double periods or spacing issues
                df["step2_output"] = df["step2_output"].apply(text_processor.clean_text)
                
                # Add the numbered sentences column
                df["step2_output_numbered_sentences"] = df["step2_output"].apply(convert_to_numbered_sentences)
                
                # Display a sample of the numbered sentences for verification
                if len(df) > 0:
                    print("\nSample of numbered sentences:")
                    sample_text = df.iloc[0]["step2_output_numbered_sentences"]
                    print(sample_text[:500] + "..." if len(sample_text) > 500 else sample_text)
                    print("\n" + "="*50)
                
                # Create all prompt variations including the numbered format
                prompts_df = df.apply(
                    lambda row: create_prompt_variants(
                        row["step2_output"],
                        row["step2_random_sent_num"],
                        row["step1_m1_output_sentence_only"],
                        numbered_text=row["step2_output_numbered_sentences"]
                    ),
                    axis=1
                )
                
                # Expand the prompts dictionary into separate columns
                for prompt_type, values in zip(prompts_df.iloc[0].keys(), zip(*prompts_df.map(lambda x: x.values()))):
                    df[f"step3_input_{prompt_type}"] = list(values)
                
                # Drop unnecessary columns
                df = df.drop(['step1_m1_output', 'step2_output_nth_sentence'], axis=1)
                
                # Save the processed dataframe to individual file
                df.to_csv(output_path, index=False, sep='|')
                
                processed_files += 1
                print(f"Processed and saved: {output_path} - Shape: {df.shape}")
            except Exception as e:
                print(f"Error processing {input_path}: {e}")
        else:
            print(f"File not found: {input_path}")
    
    print(f"Processed and saved {processed_files} files out of {len(csv_files)} possible pairs")
    
    # Print summary of duplicate analysis
    print("\n" + "="*50)
    if all_duplicates_found:
        print("⚠️ SUMMARY: Duplicate sentences were detected in the dataset!")
        print("This may affect the validity of your mirror test analysis.")
        print("Consider examining these duplicates further or filtering them out.")
    else:
        print("✅ SUMMARY: No duplicate sentences were detected in the dataset.")
        print("All sentences appear to be unique across all model pairs.")
    print("="*50)

def generate_statistics_report():
    """
    Generate a statistical report summarizing the processed data.
    This includes counts of files processed, total samples, and other relevant metrics.
    """
    print("\nGenerating statistical report...")
    
    # Collect statistics
    stats = {
        "total_files": 0,
        "total_samples": 0,
        "samples_by_model_pair": {},
        "duplicates_by_model_pair": {}
    }
    
    # Check each possible file
    for model1 in models:
        for model2 in models:
            output_path = f"{OUTPUT_DATA_PATH}mirror_test_results_{model1}_{model2}_processed.csv"
            
            if os.path.exists(output_path):
                stats["total_files"] += 1
                
                try:
                    df = pd.read_csv(output_path, sep='|')
                    sample_count = len(df)
                    stats["total_samples"] += sample_count
                    stats["samples_by_model_pair"][f"{model1} → {model2}"] = sample_count
                    
                    # Check for duplicates
                    if not df.empty and "step2_output_nth_sentence_message_only" in df.columns:
                        sentences = df["step2_output_nth_sentence_message_only"].dropna()
                        sentence_counter = Counter(sentences)
                        has_duplicates = any(freq > 1 for _, freq in sentence_counter.items())
                        stats["duplicates_by_model_pair"][f"{model1} → {model2}"] = has_duplicates
                except Exception as e:
                    print(f"Error processing statistics for {output_path}: {e}")
    
    # Print report
    print("\n" + "="*50)
    print("STATISTICAL REPORT")
    print("="*50)
    print(f"Total processed files: {stats['total_files']}")
    print(f"Total samples across all files: {stats['total_samples']}")
    
    print("\nSamples by model pair:")
    for model_pair, count in stats["samples_by_model_pair"].items():
        print(f"  {model_pair}: {count} samples")
    
    print("\nModel pairs with duplicates:")
    has_any_duplicates = False
    for model_pair, has_dups in stats["duplicates_by_model_pair"].items():
        if has_dups:
            has_any_duplicates = True
            print(f"  ⚠️ {model_pair}")
    
    if not has_any_duplicates:
        print("  ✅ No duplicates detected in any model pair")
    
    print("="*50)
    
    return stats

if __name__ == "__main__":
    # Process all CSV files
    process_csv_files()
    
    # Generate statistical report
    generate_statistics_report()